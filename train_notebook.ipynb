{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.models import resnet34\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from losses import get_losses_unlabeled, BCE_soft_labels, sigmoid_rampup\n",
    "from utils.get_data import get_data\n",
    "from model.basenet import Predictor\n",
    "from utils.utils import get_classlist"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-01 10:06:04.796 python[3276:31430] *** Assertion failure in +[NSEvent otherEventWithType:location:modifierFlags:timestamp:windowNumber:context:subtype:data1:data2:], NSEvent.m:647\n",
      "2023-04-01 10:06:04.808 python[3276:31430] *** Assertion failure in +[NSEvent otherEventWithType:location:modifierFlags:timestamp:windowNumber:context:subtype:data1:data2:], NSEvent.m:647\n",
      "2023-04-01 10:06:04.822 python[3276:31430] *** Assertion failure in +[NSEvent otherEventWithType:location:modifierFlags:timestamp:windowNumber:context:subtype:data1:data2:], NSEvent.m:647\n",
      "2023-04-01 10:06:04.835 python[3276:31430] *** Assertion failure in +[NSEvent otherEventWithType:location:modifierFlags:timestamp:windowNumber:context:subtype:data1:data2:], NSEvent.m:647\n",
      "usage: ipykernel_launcher.py [-h] [--batch_size BATCH_SIZE]\n",
      "                             [--temperature TEMPERATURE]\n",
      "                             [--learning_rate LEARNING_RATE]\n",
      "                             [--train_steps TRAIN_STEPS]\n",
      "                             [--rampup_coeff RAMPUP_COEFF]\n",
      "                             [--rampup_length RAMPUP_LENGTH]\n",
      "                             [--threshold THRESHOLD]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /Users/niruhan/Library/Jupyter/runtime/kernel-466f74fe-e059-47df-97e8-02decb72de6e.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001B[0;31mSystemExit\u001B[0m\u001B[0;31m:\u001B[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/niruhan/Documents/source_codes/deeplearning-project/venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3513: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# arguments\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--batch_size', type=int, default=4)\n",
    "parser.add_argument('--temperature', type=float, default=0.05)\n",
    "parser.add_argument('--learning_rate', type=float, default=0.01)\n",
    "parser.add_argument('--train_steps', type=int, default=1000)\n",
    "parser.add_argument('--rampup_coeff', type=float, default=30.0)\n",
    "parser.add_argument('--rampup_length', type=int, default=20000)\n",
    "parser.add_argument('--threshold', default=0.95, type=float)\n",
    "logs_file = '' # ??\n",
    "checkpath = '' # ??\n",
    "\n",
    "\n",
    "args = parser.parse_args()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "resnet_output_vector_size = 1000 # ??\n",
    "\n",
    "source_annotation_path = 'data/annotations/labeled_source_images_webcam.txt'\n",
    "class_list = get_classlist(source_annotation_path)\n",
    "num_class = len(class_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "feature_extractor = resnet34(pretrained=True)\n",
    "predictor = Predictor(num_class=num_class, input_vector_size=resnet_output_vector_size, norm_factor=args.temperature)\n",
    "nn.init.xavier_normal_(predictor.fc.weight)\n",
    "# nn.init.zeros_(F.fc.bias)\n",
    "\n",
    "feature_extractor = nn.DataParallel(feature_extractor)\n",
    "predictor = nn.DataParallel(predictor)\n",
    "feature_extractor = feature_extractor.to(device)\n",
    "predictor = predictor.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "opt = {}\n",
    "opt['logs_file'] = logs_file\n",
    "opt['checkpath'] = checkpath\n",
    "opt['class_list'] = class_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "labeled_datasets, unlabled_target_dataset = get_data(args)\n",
    "\n",
    "labeled_dataloader = DataLoader(labeled_datasets, batch_size=args.batch_size, num_workers=0, shuffle=True,\n",
    "                                drop_last=True)\n",
    "unlabled_target_data_loader = DataLoader(unlabled_target_dataset, batch_size=args.batch_size, num_workers=0,\n",
    "                                         shuffle=True, drop_last=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "labeled_len = len(labeled_dataloader)\n",
    "unlabeled_len = len(unlabled_target_data_loader)\n",
    "\n",
    "print(\"hi\")\n",
    "writer = SummaryWriter()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train():\n",
    "    labeled_data_iter = iter(labeled_dataloader)\n",
    "    unlabled_data_iter = iter(unlabled_target_data_loader)\n",
    "\n",
    "    feature_extractor.train()\n",
    "    predictor.train()\n",
    "\n",
    "    optimizer_feature_extractor = optim.SGD(feature_extractor.parameters(), lr=args.learning_rate, momentum=0.9,\n",
    "                                            weight_decay=0.0005, nesterov=True)\n",
    "    optimizer_predictor = optim.SGD(predictor.parameters(), lr=args.learning_rate, momentum=0.9, weight_decay=0.0005,\n",
    "                                    nesterov=True)\n",
    "\n",
    "    BCE = BCE_soft_labels().to(device)\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "    for step in range(args.train_steps):\n",
    "\n",
    "        if step % labeled_len:\n",
    "            labeled_data_iter = iter(labeled_dataloader)\n",
    "        if step % unlabeled_len:\n",
    "            unlabled_data_iter = iter(unlabled_target_data_loader)\n",
    "\n",
    "        labeled_data_iter_next = next(labeled_data_iter)\n",
    "        labeled_data_images = labeled_data_iter_next[0].to(device)\n",
    "        labeled_data_labels = labeled_data_iter_next[1].to(device)\n",
    "        features = feature_extractor(labeled_data_images)\n",
    "        predictions = predictor(features)\n",
    "\n",
    "        cross_entropy_loss = criterion(predictions, labeled_data_labels)\n",
    "        writer.add_scalar(\"Loss/train/cross entropy\", cross_entropy_loss, step)\n",
    "\n",
    "        cross_entropy_loss.backward(retain_graph=True)\n",
    "        optimizer_feature_extractor.step()\n",
    "        optimizer_predictor.step()\n",
    "        optimizer_feature_extractor.zero_grad()\n",
    "        optimizer_predictor.zero_grad()\n",
    "\n",
    "        # calculate loss for unlabeled target data\n",
    "        unlabeled_data_iter_next = next(unlabled_data_iter)\n",
    "        unlabeled_data_images = unlabeled_data_iter_next[0].type(torch.FloatTensor).to(device)\n",
    "        unlabeled_data_images_t = unlabeled_data_iter_next[2].type(torch.FloatTensor).to(device)\n",
    "        unlabeled_data_images_t2 = unlabeled_data_iter_next[3].type(torch.FloatTensor).to(device)\n",
    "        unlabeled_data_labels = unlabeled_data_iter_next[1].to(device)\n",
    "\n",
    "        rampup = sigmoid_rampup(step, args.rampup_length)\n",
    "        w_consistency = args.rampup_coeff * rampup\n",
    "\n",
    "        adversarial_adaptive_clustering_loss, pseudo_labels_loss, consistency_loss = get_losses_unlabeled(args,\n",
    "                                            feature_extractor, predictor, unlabeled_data_images, unlabeled_data_images_t,\n",
    "                                            unlabeled_data_images_t2, unlabeled_data_labels, BCE, w_consistency, device)\n",
    "\n",
    "        loss = adversarial_adaptive_clustering_loss + pseudo_labels_loss + consistency_loss\n",
    "        writer.add_scalar(\"Loss/train/unlabeled\", loss, step)\n",
    "        loss.backward()\n",
    "        optimizer_feature_extractor.step()\n",
    "        optimizer_predictor.step()\n",
    "        optimizer_feature_extractor.zero_grad()\n",
    "        optimizer_predictor.zero_grad()\n",
    "\n",
    "        if step % 10 == 0:\n",
    "            print(\"step: \" + str(step) + \". ce loss: \" + str(cross_entropy_loss) + \". unlabeled loss: \" + str(loss))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train()\n",
    "writer.flush()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}